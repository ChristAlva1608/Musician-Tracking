# Configuration for Detecting 2 People - Landmark Extraction (Full Frames)
# This configuration extracts landmarks for 2 people with bad gesture detection OFF
# Video: VID_20250709_191503_00_007-fm.mp4

bad_gestures:
  # ALL BAD GESTURE DETECTION DISABLED FOR LANDMARK EXTRACTION ONLY
  detect_fingers_pointing_up: false
  detect_hunched_back: false
  detect_low_wrists: false
  detect_turtle_neck: false
  thresholds:
    finger_vertical_angle: 45  # Angle from vertical in degrees (pinky detection)
    spine_vertical_angle: 20  # Spine tilt from vertical (hunched back method 1)
    upper_lower_spine_angle: 160  # Upper/lower spine angle (hunched back method 2)
    low_wrist_threshold: 0.1
    turtle_neck_angle: 30

database:
  batch_size: 50
  batch_timeout: 5
  enabled: true  # ENABLED - Store landmarks to database
  link_frame_to_transcript: false  # Transcript disabled
  save_transcript_segments: false  # Transcript disabled
  store_chunk_video_alignment: true
  store_musician_frame_analysis: true  # IMPORTANT: Store all landmark data
  store_processing_jobs: true
  store_transcript_video: false
  table_name: musician_frame_analysis
  # Database type: 'local' for local PostgreSQL, 'supabase' for Supabase
  use_database_type: local
  # Supabase Configuration
  supabase:
    url: 'https://zjrpvldbweqilzqxwfpi.supabase.co'
    anon_key: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpqcnB2bGRid2VxaWx6cXh3ZnBpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTQ2NjgzNjIsImV4cCI6MjA3MDI0NDM2Mn0.qDw7MxugzaWllJsAZUytCHvLIRCvn2gTtR06gLmoiDk'
  # Local PostgreSQL Configuration
  local:
    host: localhost
    port: 5432
    name: musician-tracking
    user: christalva
    password: ''

detection:
  # ============================================
  # MULTI-PERSON DETECTION SETTINGS (2 PEOPLE)
  # ============================================
  num_poses: 2       # Detect 2 people (one pose per person)
  num_hands: 4       # Detect 4 hands total (2 hands per person)
  num_faces: 2       # Detect 2 faces (one face per person)

  use_two_stage_hand: false  # Use two-stage hand detection for higher accuracy

  # Model selection - OPTIMIZED FOR LANDMARK EXTRACTION
  hand_model: mediapipe      # MediaPipe for 3D hand landmarks
  pose_model: mediapipe      # MediaPipe for 3D world coordinates
  facemesh_model: yolo+mediapipe  # YOLO for face detection + MediaPipe for landmarks
  transcript_model: none     # DISABLED - Not needed for landmark extraction

  # Confidence thresholds
  hand_confidence: 0.5
  pose_confidence: 0.5
  facemesh_confidence: 0.5
  face_confidence: 0.5

  # Transcript settings (DISABLED for faster processing)
  transcript_settings:
    chunk_duration: 15
    enabled: false  # DISABLED - Not needed for landmark extraction
    language: en
    model_size: tiny

  # Model paths
  yolo_face_model_path: src/checkpoints/yolov8n-face.pt

heatmap:
  enabled: false
  gaussian_sigma: 10
  resolution:
  - 640
  - 480
  update_interval: 5

integrated_processor:
  aligned_videos_dir: src/output/aligned_videos
  alignment_directory: /Volumes/Extreme_Pro/Mitou Project/Musician-Tracking/src/video/multi-cam video/vid_shot1/original_video
  check_existing_alignment: true
  create_aligned_videos: true
  detection_output_format: mp4
  detection_videos_dir: src/output/annotated_detection_videos
  detector_config:
    database:
      enabled: true
    display_output: true  # Show visualization window during processing
    video:
      generate_report: true
      preserve_audio: true
      process_matching_duration_only: true
      save_output_video: true
      use_webcam: false
  limit_processing_duration: true  # Set to false to process entire videos without time limit
  max_processing_duration: 30  # Only used if limit_processing_duration is true
  preserve_original_audio: true
  processing_type: full_frames  # Options: 'use_offset' (skip to sync point), 'full_frames' (process entire video)
  run_detection: true
  unified_video_config:
    add_camera_labels: true
    background_color:
    - 0
    - 0
    - 0
    freeze_frame_behavior: true
    label_color:
    - 255
    - 255
    - 255
    label_font_scale: 1
    output_filename: unified_detection_output.mp4
    stack_direction: vertical  # Options: 'vertical' (stack top-to-bottom), 'horizontal' (stack left-to-right)
  unified_videos: true
  unified_videos_dir: src/output/unified_videos

logging:
  level: INFO
  log_file: tracking.log
  save_to_file: true

performance:
  buffer_size: 100
  gpu_enabled: true
  max_workers: 4

video:
  display_output: true  # Show processing window
  generate_report: true  # Generate detection statistics report
  output_format: mp4
  output_video_path: src/output/annotated_video_VID_20250709_191503_00_007-fm.mp4
  preserve_audio: true
  process_matching_duration_only: false  # FULL FRAMES - Process entire video
  report_path: src/analysis/2person_landmarks_report_fm.txt
  save_output_video: true  # Save annotated video with landmarks
  skip_frames: 0  # Process every frame (no skipping)
  source_path: /Users/christalva/Desktop/Computer Science Hub/Mitou Project/Musician-Tracking/src/video/VID_20250709_203100_00_010-fm.mp4
  temp_video_path: src/output/temp_video_no_audio.mp4
  use_webcam: false

video_aligner:
  alignment:
    correlation_threshold: 0.3
    enable_chunk_processing: true  # Options: true (multi-chunk videos like cam_1_1.mp4, cam_1_2.mp4), false (single files like cam_1.mp4)
    max_offset_search: 60
  alignment_directory: /Volumes/Extreme_Pro/Mitou Project/Musician-Tracking/src/video/multi-cam video/vid_shot1/original_video
  audio:
    extraction_duration: 120
    sample_rate: 22050
    window_ms: 100
  chunk_processing:
    chunk_gap_threshold: 60
    combine_chunks: true
    gap_frame_repeat_duration: 1
  output_video_path: src/output/original_video.mp4
  save_output_videos: true
