# Modular Video Processing System

Refactored video processing pipeline with independent, testable components.

## Architecture

```
src/processors/
â”œâ”€â”€ base_processor.py          # Base class with error handling
â”œâ”€â”€ alignment_checker.py       # Step 1: Check existing alignment data
â”œâ”€â”€ alignment_analyzer.py      # Step 2: Analyze video alignment
â”œâ”€â”€ video_aligner.py          # Step 3: Create aligned videos
â”œâ”€â”€ detection_processor.py    # Step 4: Run detection (pose, hand, face, emotion, transcript)
â””â”€â”€ unified_video_creator.py  # Step 5: Create unified/stacked videos
```

## Key Features

âœ… **Independent Testing**: Test each step separately
âœ… **Fail-Fast**: Stops immediately on missing dependencies or errors
âœ… **Clear Error Messages**: Provides installation instructions for missing packages
âœ… **Modular Design**: Easy to maintain and extend

## Error Handling

Each processor validates:
1. **Dependencies**: Required Python packages
2. **Inputs**: Configuration and file paths
3. **Processing**: Step-specific logic

If any validation fails, the processor:
- Prints clear error message
- Provides fix instructions (e.g., pip install commands)
- Raises specific exception type
- **STOPS execution immediately** (no continuation)

## Testing Individual Processors

### Test Detection Processor (Includes Transcript)

The detection processor is the most important for testing as it includes all detection features (pose, hand, face, emotion, transcript).

```bash
# Basic test (processes full video)
python src/test_detection_processor.py \
  --video /path/to/video.mp4 \
  --camera cam_1

# Test with duration limit (first 60 seconds only)
python src/test_detection_processor.py \
  --video /path/to/video.mp4 \
  --camera cam_1 \
  --max-duration 60

# Test with offset (skip first 10 seconds)
python src/test_detection_processor.py \
  --video /path/to/video.mp4 \
  --camera cam_1 \
  --offset 10.0 \
  --processing-type use_offset

# Test with custom config
python src/test_detection_processor.py \
  --video /path/to/video.mp4 \
  --camera cam_1 \
  --config src/config/custom_config.yaml
```

### Test Options

| Option | Description | Default |
|--------|-------------|---------|
| `--video, -v` | Path to video file | **Required** |
| `--camera, -c` | Camera prefix/name | `test_camera` |
| `--config` | Config file path | `src/config/config_v1.yaml` |
| `--offset` | Camera offset (seconds) | `0.0` |
| `--processing-type` | `use_offset` or `full_frames` | `full_frames` |
| `--max-duration` | Max duration to process (seconds) | None (full video) |

## Configuration for Transcript Testing

To test transcript processing specifically, ensure your config has:

```yaml
detection:
  transcript_model: "whisper"  # Enable transcript
  transcript_settings:
    whisper:
      model_size: "base"  # or "tiny", "small", "medium", "large"
      language: null  # Auto-detect, or specify "en", "ja", etc.

database:
  enabled: true  # To save transcript to database

video:
  save_output_video: true  # Save annotated video
  generate_report: true    # Generate analysis report
```

## Expected Output

When running detection processor test:

```
==============================================================================
DETECTION PROCESSOR TEST
==============================================================================
Video: /path/to/video.mp4
Camera: cam_1
Processing type: full_frames
Session ID: test_detection_20250122_143022

============================================================
DetectionProcessor - Dependency Validation
============================================================
   âœ… opencv-python available
   âœ… numpy available
   âœ… mediapipe available
   âœ… ultralytics available
   âœ… Whisper (transcript) available
   âš ï¸  DeepFace not available - emotion detection may be limited
âœ… All dependencies validated

============================================================
DetectionProcessor - Input Validation
============================================================
   ğŸ“ Output directory: src/output/annotated_detection_videos
   ğŸ¬ Processing 1 videos
âœ… All inputs validated

============================================================
DetectionProcessor - Processing
============================================================
======================================================================
Processing: cam_1
Video: /path/to/video.mp4
======================================================================
â±ï¸  [Detection for cam_1] Starting...

ğŸ”§ Initializing detector...
âœ… DetectorV2 initialized
ğŸ“ Session ID: test_detection_20250122_143022_cam_1
ğŸ¤š Hand Model: mediapipe
ğŸƒ Pose Model: mediapipe
ğŸ˜Š Face Model: mediapipe
ğŸ˜¢ Emotion Model: none
ğŸ¤ Transcript Model: whisper
âš ï¸ Bad Gestures: Enabled
ğŸ’¾ Database: Enabled

   ğŸ¬ Mode: Full frames (no duration limit)
   ğŸ“Š Offset: 0.000s

   ğŸ“‹ Detection Configuration:
      ğŸ“¹ Input: /path/to/video.mp4
      ğŸ¬ Output: src/output/annotated_detection_videos/vid_cam_1_20250122_143022.mp4
      ğŸ’¾ Database: True
      ğŸ“Š Session: test_detection_20250122_143022_cam_1
      â±ï¸  Offset: 0.000s
      ğŸšï¸  Save video: True
      ğŸ”Š Audio: True
      ğŸ“„ Report: True

ğŸ¬ Starting video processing...
[Detection progress updates...]
âœ… Detection complete for cam_1

â±ï¸  [Detection for cam_1] Completed in 2m 34.56s

======================================================================
âœ… Detection complete: 1/1 videos processed
======================================================================

âœ… Processing completed successfully

==============================================================================
TEST COMPLETED SUCCESSFULLY
==============================================================================
âœ… Processed 1/1 videos

Output videos:
  cam_1: src/output/annotated_detection_videos/vid_cam_1_20250122_143022.mp4
```

## Error Examples

### Missing Dependency

```
âŒ DEPENDENCY ERROR: Missing required packages: openai-whisper
   Install with: pip install openai-whisper
   Processing stopped. Please install missing dependencies.
```

### Missing Video File

```
âŒ VALIDATION ERROR: Video files not found:
  - cam_1: /path/to/missing.mp4
   Processing stopped. Please check your configuration.
```

### Processing Error

```
âŒ PROCESSING ERROR: Face detection failed: No faces detected in video
   This may indicate no faces were detected or face model not properly configured.
   Processing stopped.
```

## Integration with Full Pipeline

The modular processors are designed to be used in `integrated_video_processor.py`. Each processor can be:

1. **Run independently** for testing
2. **Integrated** into the full pipeline
3. **Configured** via YAML config files
4. **Validated** before execution

## Next Steps

1. **Test detection processor**: Start with a short video to verify transcript works
2. **Check output**: Look for transcript data in database and output video
3. **Adjust config**: Fine-tune transcript settings (model size, language)
4. **Scale up**: Once working, process full videos

## Troubleshooting

### Whisper Not Found
```bash
pip install openai-whisper
```

### ffmpeg Not Found (for audio processing)
```bash
# Mac
brew install ffmpeg

# Linux
sudo apt-get install ffmpeg
```

### Database Connection Failed
```bash
# Check your database credentials in config
# Ensure PostgreSQL/Supabase is running
```

### Out of Memory (Whisper)
```yaml
# Use smaller whisper model in config
transcript_settings:
  whisper:
    model_size: "tiny"  # or "base" instead of "large"
```
